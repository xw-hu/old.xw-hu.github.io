<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Xiaowei Hu, huxiaowei, xiaowei hu, Hu Xiaowei, Xiaowei, cse, cuhk, The Chinese University of Hong Kong, scut, South China University of Technology"> 
<meta name="description" content="Xiaowei Hu is a Research Scientist at Shanghai AI Laboratory">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Xiaowei Hu's homepage, The Chinese University of Hong Kong</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
	
<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#">Home</a>
        <a href="#biography">Biography</a>
        <a href="#publications">Publications</a>
	<a href="#awards">Awards</a>
        <a href="#students">Students</a>
        <a href="#service">Service</a>
        <a href="">CV</a>
    </div>
</nav>
	
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Xiaowei Hu </font></h1>  <h1><font face="Arial"> 胡枭玮 </font></h1>
				</div>

				<h3><font face="Arial"> Research Scientist </font></h3>
				<p><font face="Arial"> 
					37F-128, Shanghai AI Laboratory, <br>
					701 Yunjin Road, Xuhui District, <br>
					Shanghai, China. <br>
					<br>
					<em>Email: <a href="mailto:huxiaowei@pjlab.org.cn">huxiaowei@pjlab.org.cn</a> </em> <br>
				        <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="mailto:xwhu@cse.cuhk.edu.hk">xwhu@cse.cuhk.edu.hk</a></em> <br>
					<!-- <a href="https://xw-hu.github.io/XiaoweiHu.pdf"><em>[Curriculum Vitae]</em></a> -->
				</font></p>
				<!--<p> <a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/xw-hu"><img src="./pic/github_s.jpg" height="20px" style="margin-bottom:-3px"></a>
					<a href="https://www.facebook.com/xiaowei.hu.102"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
				</p> -->
			</td>
			<td>
				<img src="./pic/XW.jpg" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>


<!-- <br /> -->
	
<div id="biography">
<h2><font face="Arial"> Biography </font></h2>
<p style="text-align:justify"><font face="Arial">
	
	I am currently working as a research scientist in <a href="http://www.shlab.org.cn/">Shanghai AI Laboratory</a>. Before that, I was a postdoctoral fellow in the Chinese University of Hong Kong. 
	I obtained my Ph.D. degree in <a href="http://www.cse.cuhk.edu.hk/">Department of Computer Science and Engineering</a>, 
	<a href="http://www.cuhk.edu.hk/">The Chinese University of Hong Kong (CUHK)</a> in 2020, supervised by Prof. <a href="http://www.cse.cuhk.edu.hk/~pheng" target="_blank">
	Pheng-Ann Heng</a> and Prof. <a href="https://www.cse.cuhk.edu.hk/~cwfu/" target="_blank"> Chi-Wing Fu</a>, and obtained my B. Eng. degree in <a href="http://www.scut.edu.cn/cs/">School of Computer Science and Engineering</a>,
	<a href="http://www.scut.edu.cn/new/">South China University of Technology (SCUT)</a> in 2016.
	
</font></p> 
<p style="text-align:justify"><font face="Arial">
	My research interests cover computer vision, deep learning, and low-level vision. Specifically, we focus on 1) designing learning algorithms to solve vision problems under adverse weather and lighting conditions (e.g., shadow image analysis, rain/haze removal); 
	2) developing intelligent perception methods for general computer vision tasks (e.g., classification, detection, and segmentation); 3) building the next-generation computer vision models to process multiple tasks with various supervisions to better understand and create the visual world.
</font></p>

<p style="color:red; text-align:justify;"><font face="Arial">
	I am looking for self-motivated Postdoc/RA/Interns, who are interested in artificial intelligence for computer vision, machine learning, and high/low-level vision. 
	The salaries will be highly competitive. Welcome to drop me an email with your CV. Remote collaboration is also welcome!
</p>

<!-- 
	<h2><font face="Arial"> News </font></h2>
<ul style="list-style-type:none">
   <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3">
      
      [03/2021] One paper accepted to CVPR 2021 (Oral) <br>
      [12/2020] Two papers accepted to IEEE TIP <br>
      [06/2020] Passed the oral defense and became a <span style="color:rgb(224, 145, 92)"><b>Dr.</b></span> <br>
      [06/2020] Doctoral Consortium Award of CVPR 2020 (Mentor: <a href="http://www.cse.yorku.ca/~mbrown/">Michael S. Brown</a>) [<a href="http://cvpr20.com/doctoral-consortium/">link</a>] <br>
      [02/2020] One paper accepted to CVPR 2020 <br>
      [10/2019] Best Oral Presentation Award of Hong Kong Computer Vision Workshop 2019 <br>
      [09/2019] Outstanding Reviewer of ICCV 2019 <br>
      [07/2019] Two papers accepted to ICCV 2019 <br>
      [05/2019] One paper accepted to IEEE TPAMI <br>
      [02/2019] One paper accepted to CVPR 2019 <br>
      [07/2018] One paper accepted to ECCV 2018 <br>
      [02/2018] One paper accepted to CVPR 2018 (Oral) <br> 
   </font></p>
</ul>
 -->

	
<div id="publications">
<h2><font face="Arial"> Publications </font>  <font face="Arial" size="3"><a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en">[Google Scholar]</a></font> </h2>

<p><font face="Arial" size="3">Summary: TPAMI, CVPR, ICCV & ECCV (9), IEEE Transactions (15). </font> </p>
	
<!-- <p><font face="Arial"><a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en">Google Scholar</a></font></p> -->
<!-- <ul style="list-style-type:none"> -->
<!-- <p><font face="Arial">[<a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en">Google Scholar</a>] Summary: TPAMI/CVPR/ICCV/ECCV (6), IEEE Transactions (6). 
	</font>
	</p> -->
<!-- <ul style="list-style-type:none"> -->

	
<p><font face="Arial" size="4"><b>2022</b></font></p> 
<ul>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance Shadow Detection with A Single-Stage Detector <br> 
         <i> Tianyu Wang, <b>Xiaowei Hu*</b>, Pheng-Ann Heng, and Chi-Wing Fu. (* corresponding author) </i><br> 
	       IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), accepted, 2022. <br>
          </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Enhancing Pseudo Label Quality for Semi-Supervised Domain-Generalized Medical Image Segmentation <br> 
         <i>   Huifeng Yao, <b>Xiaowei Hu</b>, and Xiaomeng Li. </i><br> 
	       AAAI Conference on Artificial Intelligence (<b>AAAI</b>), accepted, 2022. <br>
	  </font>
	 </p> </li>	
</ul>		
<p><font face="Arial" size="4"><b>2021</b></font></p> 
<ul>
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Revisiting Shadow Detection: A New Benchmark Dataset for Complex World <br> 
         <i>   <b>Xiaowei Hu</b>, Tianyu Wang, Chi-Wing Fu, Yitong Jiang, Qiong Wang, and Pheng-Ann Heng. </i><br> 
	       IEEE Transactions on Image Processing (<b>IEEE TIP</b>), vol. 30, pp. 1925-1934, 2021. <br>
	    [<a href="https://ieeexplore.ieee.org/document/9319520">paper</a>]
	    [<a href="https://arxiv.org/abs/1911.06998">arXiv</a>]
	    [<a href="https://github.com/xw-hu/CUHK-Shadow#cuhk-shadow-dateset">CUHK-Shadow dataset</a>]
	    [<a href="https://github.com/xw-hu/CUHK-Shadow#cuhk-shadow-evaluation">evaluation function</a>]
	    [<a href="https://github.com/xw-hu/FSDNet">code</a>] 
	  </font>
	 </p> </li>	
	
	
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Single-Image Real-Time Rain Removal Based on Depth-Guided Non-Local Features <br> 
         <i>   <b>Xiaowei Hu</b>, Lei Zhu, Tianyu Wang, Chi-Wing Fu, and Pheng-Ann Heng.  </i><br> 
	       IEEE Transactions on Image Processing (<b>IEEE TIP</b>), vol. 30, pp. 1759-1770, 2021. <br>
	 [<a href="https://ieeexplore.ieee.org/document/9318521">paper</a>]
	 [<a href="https://github.com/xw-hu/DGNL-Net/">code</a>] 
	 [<a href="https://www.cityscapes-dataset.com/downloads/">RainCityscapes dataset</a>]  
	 </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Single-Stage Instance Shadow Detection with Bidirectional Relation Learning <br> 
         <i>   Tianyu Wang^, <b>Xiaowei Hu</b>^, Chi-Wing Fu, and Pheng-Ann Heng. (^ joint first authors) </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 1-11, 2021. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Single-Stage_Instance_Shadow_Detection_With_Bidirectional_Relation_Learning_CVPR_2021_paper.pdf">paper</a>]
	    [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Single-Stage_Instance_Shadow_CVPR_2021_supplemental.pdf">supp.</a>]
	    [<a href="https://youtu.be/p0b_2SsFypw">video</a>] 
	    [<a href="https://github.com/stevewongv/SSIS">code</a>] 
	    [<a href="https://xw-hu.github.io/paper_material/CVPR21_SSIS_poster.pdf">poster</a>] 
	  </font>
	 </p> </li>	   
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SAC-Net: Spatial Attenuation Context for Salient Object Detection <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, Tianyu Wang, and Pheng-Ann Heng. </i><br> 
	        IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 31, no. 3, pp. 1079-1090, 2021. <br>
	 [<a href="https://ieeexplore.ieee.org/document/9094635">paper</a>]
	 [<a href="https://arxiv.org/abs/1903.10152">arXiv</a>]
	 [<a href="https://ieeexplore.ieee.org/document/9094635/media#media">supp.</a>]
	 [<a href="https://github.com/xw-hu/SAC-Net">code</a>] 
	 [<a href="https://drive.google.com/open?id=1Z2WV39lxeyDBXlpNFhoxYgOmwWsoQutX">results</a>]
	  </font>
	 </p> </li>    
	
   
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Texture-Aware Features for Camouflaged Object Detection <br> 
         <i>   Jingjing Ren^, <b>Xiaowei Hu</b>^, Lei Zhu, Xuemiao Xu, Yangyang Xu, Weiming Wang, Zijun Deng, and Pheng-Ann Heng. (^ joint first authors)  </i><br> 
	        IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), accepted, 2021. <br>
	        [<a href="https://ieeexplore.ieee.org/document/9606888">paper</a>]
	  </font>
	 </p> </li>  
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rotation-oriented Collaborative Self-supervised Learning for Retinal Disease Diagnosis  <br> 
	 <i>  Xiaomeng Li, <b>Xiaowei Hu</b>, Xiaojuan Qi, Lequan Yu, Wei Zhao, Pheng-Ann Heng, and Lei Xing. </i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 40, no. 9, pp. 2284-2294, 2021. (<span style="color:rgb(224, 145, 92)"><b>TMI Popular Paper</b></span>) <br>  
	      [<a href="https://ieeexplore.ieee.org/document/9411868">paper</a>]
	      [<a href="https://github.com/xmengli/Rotation-oriented-self-supervised">code</a>] 
	 </font>
	 </p> </li>

    
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SALMNet: A Structure-Aware Lane Marking Detection Network <br> 
         <i>  Xuemiao Xu, Tianfei Yu, <b>Xiaowei Hu</b>, Wing W. Y. Ng, and Pheng-Ann Heng. </i><br> 
              IEEE Transactions on Intelligent Transportation Systems (<b>IEEE TITS</b>), vol. 22, no. 8, pp. 4986-4997, 2021. <br>
	        [<a href="https://ieeexplore.ieee.org/document/9061152">paper</a>]
	 </font>
	 </p> </li>
	
	
   
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Gated Non-Local Residual for Single-Image Rain Streak Removal <br> 
         <i>  Lei Zhu, Zijun Deng, <b>Xiaowei Hu</b>, Haoran Xie, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng. </i><br> 
              IEEE Transactions on Circuits and Systems for Video Technology  (<b>IEEE TCSVT</b>), vol. 31, no. 6, pp. 2147-2159, 2021. <br> 
	        [<a href="https://ieeexplore.ieee.org/document/9187841">paper</a>]
	 </font>
	 </p> </li>
    
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection  <br> 
	 <i>   Xudong Yan, Huaidong Zhang, Xuemiao Xu, <b>Xiaowei Hu</b>, and Pheng-Ann Heng. </i><br> 
               AAAI Conference on Artificial Intelligence (<b>AAAI</b>), vol. 35, no. 4, pp. 3110-3118, 2021. <br>
	      [<a href="https://www.aaai.org/AAAI21Papers/AAAI-4221.YanX.pdf">paper</a>]
	      [<a href="https://github.com/Xudong-Yan/SCADN">code</a>] 
	 </font>
	 </p> </li> 

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Global Guidance Network for Breast Lesion Segmentation in Ultrasound Images  <br> 
	 <i>  Cheng Xue, Lei Zhu, Huazhu Fu, <b>Xiaowei Hu</b>, Xiaomeng Li, Hai Zhang, and Pheng-Ann Heng. </i><br> 
              Medical Image Analysis (<b>MedIA</b>), vol. 70, article no. 101989, 2021. <br> 
	      [<a href="https://www.sciencedirect.com/science/article/pii/S1361841521000359">paper</a>]
	 </font>
	 </p> </li>
	
	
</ul>	
<p><font face="Arial" size="4"><b>2020</b></font></p> 
<ul>
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Direction-Aware Spatial Context Features for Shadow Detection and Removal <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), vol. 42, no. 11, pp. 2795-2808, 2020. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8723605">paper</a>]
	 [<a href="https://arxiv.org/abs/1805.04635">arXiv</a>]
	 [<a href="https://ieeexplore.ieee.org/document/8723605/media#media">supp.</a>]
	 [<a href="https://github.com/xw-hu/DSC">code</a>] </font>
	 </p> </li>	
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance Shadow Detection <br> 
         <i>   Tianyu Wang^, <b>Xiaowei Hu</b>^, Qiong Wang, Pheng-Ann Heng, and Chi-Wing Fu. (^ joint first authors) </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 1880-1889, 2020. <br>
	    [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Instance_Shadow_Detection_CVPR_2020_paper.pdf">paper</a>]
	    [<a href="https://arxiv.org/abs/1911.07034">arXiv</a>]
	    [<a href="https://github.com/stevewongv/InstanceShadowDetection">code</a>]
	    [<a href="https://drive.google.com/file/d/1oOzRUiYiZo1T_OeTTqLebxWZadGTeBIY/view">SOBA dataset</a>]
	    [<a href="https://drive.google.com/file/d/1VHP8qm_FZeKR6_zMtNt3SxvBTvfEK7I8/view">results</a>]
	    [<a href="https://crossminds.ai/video/instance-shadow-detection-5f6e7779d81cf36f1a8e32a8/">video</a>] 
	  </font>
	 </p> </li>	
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Saliency-Aware Texture Smoothing <br> 
         <i>   Lei Zhu^, <b>Xiaowei Hu</b>^, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng. (^ joint first authors) </i><br> 
	       IEEE Transactions on Visualization and Computer Graphics (<b>IEEE TVCG</b>), vol. 26, no. 7, pp. 2471-2484, 2020. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8585158">paper</a>]
	 [<a href="https://github.com/xw-hu/GNLB">code</a>] 
	 [<a href="https://drive.google.com/file/d/1vo7kYFyaPRYQtj8b196sXy2FoN8oPnNZ">SDTS dataset</a>] </font>
	 </p> </li>	

	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Ψ-Net: Stacking Densely Convolutional LSTMs for Sub-cortical Brain Structure Segmentation  <br> 
	 <i>  Lihao Liu^, <b>Xiaowei Hu</b>^, Lei Zhu, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng. (^ joint first authors) </i><br>
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 39, no. 9, pp. 2806-2817, 2020. <br>
	      [<a href="https://ieeexplore.ieee.org/document/9007625">paper</a>]
	 </font>
	 </p> </li>
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            CANet: Cross-disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading  <br> 
	 <i>   Xiaomeng Li, <b>Xiaowei Hu</b>, Lequan Yu, Lei Zhu, Chi-Wing Fu, and Pheng-Ann Heng.</i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 39, no. 5, pp. 1483-1493, 2020. <br> 
	 [<a href="https://ieeexplore.ieee.org/document/8892667">paper</a>]
         [<a href="https://github.com/xmengli999/CANet">code</a>] 
	 </font>
	 </p> </li>
	
      
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            GrabAR: Occlusion-aware Grabbing Virtual Objects in AR <br> 
         <i>   Xiao Tang, <b>Xiaowei Hu</b>, Chi-Wing Fu, and Daniel Cohen-Or. </i><br> 
	       ACM Symposium on User Interface Software and Technology (<b>UIST</b>), pp. 697-708, 2020. <br>
	    [<a href="https://dl.acm.org/doi/abs/10.1145/3379337.3415835">paper</a>]
	    [<a href="https://arxiv.org/abs/1912.10637">arXiv</a>]
	    [<a href="https://wbstx.github.io/grabar/">project</a>] 
	  </font>
	  </p> </li>
	
   
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Aggregating Attentional Dilated Features for Salient Object Detection  <br> 
	 <i>   Lei Zhu, Jiaxing Chen, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng.</i><br> 
              IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 30, no. 10, pp. 3358-3371, 2020. <br> 
	 [<a href="https://ieeexplore.ieee.org/document/8836095">paper</a>]
	 [<a href="https://github.com/githubBingoChen/AADF-Net">code</a>]
	 [<a href="https://drive.google.com/file/d/1tv72yWNH0ANHoSU4qMOwD7g5r53wSZEe/view">results</a>]
	 </font>
	 </p> </li>

	
</ul>	
<p><font face="Arial" size="4"><b>2019</b></font></p> 
<ul>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Mask-ShadowGAN: Learning to Remove Shadows from Unpaired Data <br> 
         <i>   <b>Xiaowei Hu</b>, Yitong Jiang, Chi-Wing Fu, and Pheng-Ann Heng. </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), pp. 2472-2481, 2019. <br>
	 [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Hu_Mask-ShadowGAN_Learning_to_Remove_Shadows_From_Unpaired_Data_ICCV_2019_paper.pdf">paper</a>]
	 [<a href="https://arxiv.org/abs/1903.10683">arXiv</a>]
	 [<a href="https://github.com/xw-hu/Mask-ShadowGAN">code</a>] 
	 [<a href="https://drive.google.com/open?id=1PPAX0W4eyfn1cUrb2aBefnbrmhB1htoJ">USR dataset</a>]  
	 [<a href="https://xw-hu.github.io/paper_material/ICCV19_MaskShadowGAN_poster.pdf">poster</a>]  
	  </font>
	 </p> </li>	
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Multi-Model Fusion for Single-Image Dehazing <br> 
         <i>   Zijun Deng, Lei Zhu, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Qing Zhang, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), pp. 2453-2462, 2019. <br> 
	    [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Deep_Multi-Model_Fusion_for_Single-Image_Dehazing_ICCV_2019_paper.pdf">paper</a>]
	    [<a href="https://github.com/zijundeng/DM2F-Net">code</a>] 
	    [<a href="https://drive.google.com/drive/folders/1ZVBI_3Y2NthVLeK7ODMIB5vRjmN9payF">results</a>]
	  </font>
	 </p> </li>	
	


    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Depth-Attentional Features for Single-Image Rain Removal <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, and Pheng-Ann Heng.  </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 8022-8031, 2019. <br>
	 [<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_Depth-Attentional_Features_for_Single-Image_Rain_Removal_CVPR_2019_paper.pdf">paper</a>]
	 [<a href="http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Hu_Depth-Attentional_Features_for_CVPR_2019_supplemental.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/DAF-Net">code</a>] 
	 [<a href="https://www.cityscapes-dataset.com/downloads/">RainCityscapes dataset</a>]  
	 [<a href="https://xw-hu.github.io/paper_material/CVPR19_derain_poster.pdf">poster</a>]  
	 </font>
	 </p> </li>	

	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SINet: A Scale-Insensitive Convolutional Neural Network for Fast Vehicle Detection  <br> 
         <i>  <b>Xiaowei Hu</b>, Xuemiao Xu, Yongjie Xiao, Hao Chen, Shengfeng He, Jing Qin, and Pheng-Ann Heng. </i> <br> 
              IEEE Transactions on Intelligent Transportation Systems (<b>IEEE TITS</b>), vol. 20, no. 3, pp. 1010-1019, 2019. <br>
	      <span style="color:rgb(224, 145, 92)"><b>ESI Highly Cited Paper</b></span> <br>
	 [<a href="https://ieeexplore.ieee.org/document/8478157">paper</a>]
	 [<a href="https://arxiv.org/abs/1804.00433">arXiv</a>]
	 [<a href="https://github.com/xw-hu/SINet">code</a>] 
	 [<a href="https://drive.google.com/file/d/1raH0LF-hADB4BZmU9SAv19EWV6dxyQAw/view">LSVH dataset (Google)</a>]
	 [<a href="https://pan.baidu.com/s/1lrasgXOUVC-qX_yb6t1fKA">LSVH dataset (Baidu)</a>] </font>
	 </p> </li>
	

     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Probabilistic Multilayer Regularization Network for Unsupervised 3D Brain Image Registration  <br> 
	 <i>   Lihao Liu, <b>Xiaowei Hu</b>, Lei Zhu, and Pheng-Ann Heng. </i><br> 
               International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), pp. 346-354, 2019. <br>
	     [<a href="https://link.springer.com/chapter/10.1007/978-3-030-32245-8_39">paper</a>]
	     [<a href="https://arxiv.org/abs/1907.01922">arXiv</a>]
	     [<a href="https://github.com/liulihao-cuhk/Probabilistic-Multilayer-Regularization-Network">code</a>] 
	 </font>
	 </p> </li>
	
 
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound  <br> 
	 <i>   Yi Wang, Haoran Dou, <b>Xiaowei Hu</b>, Lei Zhu, Xin Yang, Ming Xu, Jing Qin, Pheng-Ann Heng, Tianfu Wang, and Dong Ni.</i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 38, no. 12, pp. 2768-2778, 2019. <br> 
	 [<a href="https://ieeexplore.ieee.org/document/8698868">paper</a>]
	 [<a href="https://arxiv.org/abs/1907.01743">arXiv</a>]
	 [<a href="https://github.com/wulalago/DAF3D">code</a>] 
	 </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Enhancing Augmented VR Interaction via Egocentric Scene Analysis  <br> 
	 <i>   Yang Tian, Chi-Wing Fu, Shengdong Zhao, Ruihui Li, Xiao Tang, <b>Xiaowei Hu</b>, and Pheng-Ann Heng.</i><br> 
              Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<b>Ubicomp</b>), <br> 
	      vol. 3, no. 3, article no. 105, 2019. <br> 
	 [<a href="https://dl.acm.org/citation.cfm?doid=3361560.3351263">paper</a>]
	 </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            CATARACTS: Challenge on Automatic Tool Annotation for cataRACT Surgery  <br> 
	 <i>  Hassan Al Hajj, Mathieu Lamard, Pierre-Henri Conze, Soumali Roychowdhury, <b>Xiaowei Hu</b>, et al.</i><br> 
              Medical Image Analysis (<b>MedIA</b>), vol. 52, pp. 24-41, 2019. <br> 
	 [<a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151830865X">paper</a>]
	 </font>
	 </p> </li>
	

	
</ul>	
<p><font face="Arial" size="4"><b>2018 & before</b></font></p> 
<ul> 
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Direction-Aware Spatial Context Features for Shadow Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lei Zhu, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 7454-7462, 2018. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br> 
	 [<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.pdf">paper</a>]
	 [<a href="https://arxiv.org/abs/1712.04142">arXiv</a>]
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_supp.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/DSC">code</a>]
	 [<a href="https://drive.google.com/open?id=1DCTqEnYJ8ADBqShBzXFYKa_yD-YZKEo7">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_poster.pdf">poster</a>]   
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_slides.pdf">slides</a>]  
	 [<a href="https://www.youtube.com/watch?v=zVYY9HaEJnc&t=1195s">video</a>] </font>
	 </p> </li>
	 <!-- Tech report, arXiv, Dec. 2017  </font><br> -->
	
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Recurrently Aggregating Deep Features for Salient Object Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lei Zhu, Jing Qin, Chi-Wing Fu, and Pheng-Ann Heng. </i><br> 
               AAAI Conference on Artificial Intelligence (<b>AAAI</b>), pp. 6943-6950, 2018. (<span style="color:rgb(224, 145, 92)"><b>Spotlight</b></span>)<br>
	 [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16775/16281">paper</a>]
	 [<a href="https://xw-hu.github.io/paper_material/AAAI18_RADF_supp.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/RADF">code</a>] 
	 [<a href="https://drive.google.com/drive/folders/0B8VpfLBo2BeyNWxnMURWNlU0YVE">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/AAAI18_RADF_poster.pdf">poster</a>]  </font>
	 </p> </li> 
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            R<sup>3</sup>Net: Recurrent Residual Refinement Network for Saliency Detection  <br> 
	 <i>   Zijun Deng^, <b>Xiaowei Hu</b>^, Lei Zhu, Xuemiao Xu, Jing Qin, Guoqiang Han, and Pheng-Ann Heng. (^ joint first authors) </i><br> 
               International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), pp. 684-690, 2018. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br>
	 [<a href="https://www.ijcai.org/proceedings/2018/0095.pdf">paper</a>]
	 [<a href="https://github.com/zijundeng/R3Net">code</a>]
	 [<a href="https://drive.google.com/open?id=1PloaTokZEfWPy8voDm7mp3yvHnXCtn2c">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/IJCAI18_R3Net_poster.pdf">poster</a>]
	 [<a href="https://xw-hu.github.io/paper_material/IJCAI18_R3Net_slides.pdf">slides</a>]
	    </font>
	 </p> </li>
	
    	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Bidirectional Feature Pyramid Network with Recurrent Attention Residual Modules for Shadow Detection  <br> 
	 <i>   Lei Zhu, Zijun Deng, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng. </i><br> 
               European Conference on Computer Vision (<b>ECCV</b>), pp. 122-137, 2018. <br>
	 [<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Lei_Zhu_Bi-directional_Feature_Pyramid_ECCV_2018_paper.pdf">paper</a>]
	 [<a href="https://github.com/zijundeng/BDRAR">code</a>]
	 [<a href="https://xw-hu.github.io/paper_material/ECCV18_BDRAR_poster.pdf">poster</a>]  
	 </font>
	 </p> </li>	
	
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Attentional Features for Prostate Segmentation in Ultrasound  <br> 
	 <i>   Yi Wang, Zijun Deng, <b>Xiaowei Hu</b>, Lei Zhu, Xin Yang, Xuemiao Xu, Pheng-Ann Heng, and Dong Ni. </i><br> 
               International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), pp. 523-530, 2018. <br>
	 [<a href="https://link.springer.com/chapter/10.1007/978-3-030-00937-3_60">paper</a>]
	 [<a href="https://github.com/zijundeng/DAF">code</a>] </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            AGNet: Attention-Guided Network for Surgical Tool Presence Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lequan Yu, Hao Chen, Jing Qin, and Pheng-Ann Heng. </i><br> 
		Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 186-194, 2017. <br>
	 [<a href="https://link.springer.com/chapter/10.1007/978-3-319-67558-9_22">paper</a>] 
	 [<a href="https://github.com/xw-hu/AGNet">code</a>] </font>
	 </p> </li>
	
</ul>
	
<!-- 
<h2><font face="Arial"> Manuscript </font></h2>
<ul>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               Deep Texture-Aware Features for Camouflaged Object Detection <br> 
         <i>   Jingjing Ren^, <b>Xiaowei Hu</b>^, Lei Zhu, Xuemiao Xu, Yangyang Xu, Weiming Wang, Zijun Deng, and Pheng-Ann Heng. (^ joint first authors) </i><br> 
	       Tech report, arXiv,  February, 2021. <br>
	    [<a href="https://arxiv.org/abs/2102.02996">arXiv</a>]
	  </font>
	 </p> </li>
    	
</ul>
-->
	
	
<div id="awards">
<h2><font face="Arial"> Honors &amp; Awards </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

	<li> Achieved Excellence in the <strong>Hong Kong Young Scientist Award</strong> in Engineering Science (two winners per year in HK) <div style="float:right; text-align:right">2021</div>
</li>
	<li><a href="https://cerg1.ugc.edu.hk/hkpfs/index.html"> Hong Kong Ph.D. Fellowship </a> (the <strong>highest</strong> scholarship for students studying in Hong Kong) <div style="float:right; text-align:right">2016-2020</div>
</li>
	
<li><a href="http://cvpr20.com/doctoral-consortium/"> CVPR Doctoral Consortium Award</a> (31 awardees <strong>globally</strong>) <div style="float:right; text-align:right">2020</div>
</li>
	
<li>Best Oral Presentation Award of Hong Kong Computer Vision Workshop (the <strong>only</strong> winner) <div style="float:right; text-align:right">2019</div>
</li>
	
<li><a href="http://iccv2019.thecvf.com/best_reviewers"> ICCV Outstanding Reviewer Award</a> (top <strong>3.6%</strong>) <div style="float:right; text-align:right">2019</div>
</li>
	
<li>Excellent Teaching Assistant at CSE Department, CUHK <div style="float:right; text-align:right">2018</div>
</li>
	
<li>Top 10 Outstanding Students at SCUT (<strong><u>rank 1st</u></strong>, the <strong>highest</strong> award for students at SCUT) <div style="float:right; text-align:right">2016</div>
</li>
	
<li>Gold Award of Pan-Pearl-River-Delta University IT Project Competition in China <div style="float:right; text-align:right">2016</div>
</li>
	
<li>Google Excellence Scholarship (one of 58 winners in <strong>China</strong>) <div style="float:right; text-align:right">2015</div>
</li>
	
<li>Tencent Outstanding Scholarship (the <strong>only</strong> undergraduate winner at SCUT) <div style="float:right; text-align:right">2015</div>
</li>
	
<li>National Scholarship (the <strong>highest</strong> national wide scholarship for undergraduate students in China) <div style="float:right; text-align:right">2013</div>
</li>
	
<!-- <li>First Prize and Best Practical Award of University IT Project Competition in Guangdong Province <div style="float:right; text-align:right">2016</div>
</li> -->
<li>First Prize of Adolescents Science &amp; Technology Innovation Contest in Hebei Province <div style="float:right; text-align:right">2011</div>
</li>
<br>
</p>
</ul>

<!-- 	
<h2><font face="Arial"> Teaching and Supervision </font></h2>
<ul style="list-style-type:none"> 
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Teaching Assistant at CUHK </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	        Advanced Topics in Computer Graphics and Visualization (Excellent Teaching Assistant), Spring 2018. <br> 
	        Digital Logic and Systems, Fall 2016-2018. <br> 
	        Linear Algebra and Vector Calculus for Engineers, Spring 2017.
	      </font> </p>
	 </li>
	
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Supervision </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	        Supervise junior Ph.D. (Tianyu Wang and Xiao Tang), M.Phil. (Zijun Deng, Lihao Liu, and Tianfei Yu), 
		and undergraduate (Yitong Jiang) students to publish research papers on top-tier conferences and journals.
	      </font> </p>
	 </li>
</ul> -->
	

<div id="students">
<h2><font face="Arial"> Students </font></h2>
<ul style="list-style-type:none"> 
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Current Students: </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	        <a href="https://stevewongv.github.io/" target="_blank"> Tianyu Wang</a> (Research Intern, PhD Student at CUHK) <br> 
	        <a href="https://jiaqixuac.github.io/" target="_blank"> Jiaqi Xu</a> (Research Intern, PhD Student at CUHK) <br> 
		<a href="https://charlespikachu.github.io/" target="_blank"> Zhenchao Jin</a> (Research Intern, incoming PhD Student at HKU) <br> 
		Sitong Wu (Research Intern, PhD Student at CAS) <br> 
		<a href="https://charliezcj.github.io/" target="_blank"> Chuanjun Zheng</a> (Research Intern, MPhil Student at SZU) <br> 
		Zhenghao Xing (Research Assistant at CUHK) <br>
	      </font> </p>
	 </li>

	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Previous Mentorship: </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<a href="https://lihaoliu-cambridge.github.io/" target="_blank"> Lihao Liu</a> (MPhil at CUHK) (now, PhD student at University of Cambridge) <br> 
		<a href="https://wbstx.github.io/" target="_blank"> Xiao Tang</a> (PhD at CUHK) <br> 
	        <a href="https://scholar.google.com/citations?user=DTLPDqkAAAAJ&hl=en" target="_blank"> Zijun Deng</a> (MPhil at SCUT) <br> 
		Yitong Jiang</a> (undergraduate at CUHK) (now, Researcher at SenseTime) <br>
	      </font> </p>
	 </li>
</ul>

	
	
<div id="service">
<h2><font face="Arial"> Professional Activities </font></h2>
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 4px; margin-bottom: 4px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Invited Talks </strong> <br> </font> </p> 

              <ul>	
		      	      
	      <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 0px; margin-bottom: 0px;"><font face="Arial" size="3"><meta charset="utf-8">
		 <i> Shadow Detection and Removal with Deep Learning </i> <br>
		     at Shanghai AI Laboratory, October, 2021. <br>
		     at TechBeat, August 2021.  [<a href="https://www.techbeat.net/talk-info?id=577">video link</a>] [<a href="https://www.bilibili.com/video/av675112288">video link (bilibili)</a>] [<a href="https://zhuanlan.zhihu.com/p/405004052">report</a>]  <br>
		     at Nanjing University, May 2021. <br>
		     at Nanjing University of Science and Technology, May 2021. <br>
		     at Nanjing University of Aeronautics and Astronautics, April 2021. <br>
		     at Institute of Computing Technology, Chinese Academy of Sciences, March 2021. <br>  
		     at Peng Cheng Laboratory Overseas Young Scientist Forum, July 2020. <br>  
		     at Shantou University, December 2019.
	      </font> </p> </li>
		      
              <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 0px; margin-bottom: 0px;"><font face="Arial" size="3"><meta charset="utf-8">
		 <i> Instance Segmentation and Instance Shadow Detection </i> <br>
		     at Nanjing University of Aeronautics and Astronautics, October 2021. <br>
	      </font> </p> </li>
		 
              <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 0px; margin-bottom: 0px;"><font face="Arial" size="3"><meta charset="utf-8">
		 <i> Mask-ShadowGAN: Learning to Remove Shadows from Unpaired Data </i>  <br> 
		     at Hong Kong Computer Vision Workshop, October 2019. (Best Oral Presentation Award) <br> 
	      </font> </p> </li>
		 
	      <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 0px; margin-bottom: 0px;"><font face="Arial" size="3"><meta charset="utf-8">
		 <i> Direction-Aware Spatial Context Features for Shadow Detection </i> <br> 
		      at AI Research Club, July 2018. <br> 
		 [<a href="http://www.mooc.ai/open/course/523">video link1</a>] 
		 [<a href="https://club.leiphone.com/page/openclassdetail/523">video link2</a>] 
	         [<a href="https://www.leiphone.com/news/201808/CbEQPq5usfUIPBpZ.html">report</a>] 
	      </font> </p> </li>
              </ul>
         </li>
	
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong>  Conference Reviews </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		  SIGGRAPH Asia'22, ECCV'22, CVPR'22, ACM MM'22, AAAI'22, ICCV'21, CVPR'21, ACM MM'21, AAAI'21, PG'21, MICCAI'21, ECCV'20, CVPR'20, AAAI'20, PG'20, MICCAI'20, ICCV'19 (Outstanding Reviewer), CVPR'19, MICCAI'19.
	      </font> </p> 

         </li>
	
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Journal Reviews </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	      IEEE TPAMI, IJCV, IEEE TIP, IEEE TMM, IEEE TITS, IEEE TMI, IEEE TCSVT, IEEE TVT, Neurocomputing, JBHI, JMLC, CUIV, Artificial Intelligence Review, The Visual Computer, Computers & Graphics, IEEE CG&A, IEEE Access.
	      </font> </p>  

         </li>
	
	 <li>  <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Reading List on Deep Learning </strong> [<a href="https://github.com/xw-hu/Reading-List">link</a>] </font> 
          </p> </li>
	
	
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong>  My Undergraduate Experiences </strong> (Chinese) <br> </font> </p>
	  
         <p style="margin-left: 20px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	        <a href="https://mp.weixin.qq.com/s/zFiKbJziHp9Lj2zBauJ6Aw"> Report 1</a>, 
	        <a href="https://mp.weixin.qq.com/s?__biz=MjM5NTA2ODQyMA==&mid=2652717099&idx=2&sn=0ebc4245ffbc6683d91ba8f1a5970217&scene=22&srcid=0627XArpyGzU3Rf2Zz7ZeIWW#rd"> Report 2</a>,  
		<a href="http://youth.100steps.net/info_view.php?tab=st&VID=205"> Report 3</a>, 
		<a href="https://mp.weixin.qq.com/s?__biz=MzA3ODcwODY2Ng==&mid=403554712&idx=1&sn=213f118f4c8719e12ce80cabc526f016&scene=23&srcid=03105VWUMlXV8EwJe4icq9Bu#rd"> Report 4</a>, 
		<a href="https://mp.weixin.qq.com/s?__biz=MjM5NTA2ODQyMA==&mid=2652717178&idx=1&sn=d2f4ba2d8a7c5f0261c6a58fcad7363f&scene=21#wechat_redirect"> Report 5</a>
	 </font> </p> 
	 </li>
</ul>
		

<div id="footer">
	<div id="footer-text"></div>
	
        <p><center>
      	<div id="clustrmaps-widget" style="width:10%">
     
      	<script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=FF2zR4KR625rREtKSURq3BrUAQIoHTFUm_j1pf6EAtU"></script>
		
        </div>
	<p><center><font face="Arial">
        <br>
            &copy; Xiaowei Hu | Last updated: May 2022.
        </font></center></p>
		
</div>
</body></html>

